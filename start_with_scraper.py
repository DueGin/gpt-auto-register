#!/usr/bin/env python3
"""
å…ˆçˆ¬å–åœ°å€ï¼Œå†å¯åŠ¨æ³¨å†ŒæœåŠ¡
ç”¨æ³•:
    python3 start_with_scraper.py --scrape 20   # çˆ¬å–20ä¸ªåœ°å€åå¯åŠ¨æœåŠ¡
    python3 start_with_scraper.py               # ç›´æ¥å¯åŠ¨æœåŠ¡
"""

import sys
import os
import subprocess
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def run_scraper(count: int):
    """è¿è¡Œçˆ¬è™«é‡‡é›†åœ°å€"""
    scraper_dir = Path("ç¾å›½åœ°å€çˆ¬è™«_å‰¯æœ¬")
    
    if not scraper_dir.exists():
        print("âŒ çˆ¬è™«ç›®å½•ä¸å­˜åœ¨: ç¾å›½åœ°å€çˆ¬è™«_å‰¯æœ¬")
        return False
    
    scraper_script = scraper_dir / "basic_fields_scraper.py"
    if not scraper_script.exists():
        print(f"âŒ çˆ¬è™«è„šæœ¬ä¸å­˜åœ¨: {scraper_script}")
        return False
    
    print(f"ğŸ•·ï¸  å¯åŠ¨çˆ¬è™«ï¼Œé‡‡é›† {count} ä¸ªåœ°å€...")
    
    try:
        # åˆ›å»ºä¸´æ—¶ Python è„šæœ¬æ¥è¿è¡Œçˆ¬è™«
        temp_scraper = scraper_dir / "temp_scraper_runner.py"
        with open(temp_scraper, 'w', encoding='utf-8') as f:
            f.write(f'''#!/usr/bin/env python3
import sys
sys.path.insert(0, ".")
from basic_fields_scraper import scrape_basic
scrape_basic(count={count}, delay=2)
''')
        
        # è¿è¡Œçˆ¬è™«
        result = subprocess.run(
            [sys.executable, "temp_scraper_runner.py"],
            cwd=str(scraper_dir),
            capture_output=False
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            temp_scraper.unlink()
        except:
            pass
        
        return result.returncode == 0
    except Exception as e:
        print(f"âŒ çˆ¬è™«æ‰§è¡Œå¤±è´¥: {e}")
        return False

def start_service():
    """å¯åŠ¨ Web æœåŠ¡"""
    print("\nğŸš€ å¯åŠ¨æ³¨å†ŒæœåŠ¡...")
    print("ğŸ“º è®¿é—®: http://localhost:7070")
    print("ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢\n")
    
    try:
        from waitress import serve
        import server
        
        serve(server.app, host='0.0.0.0', port=7070, threads=6)
    except KeyboardInterrupt:
        print("\nâœ… æœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description='çˆ¬å–åœ°å€å¹¶å¯åŠ¨æœåŠ¡')
    parser.add_argument('--scrape', type=int, help='é‡‡é›†æŒ‡å®šæ•°é‡çš„åœ°å€')
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®å¹¶æ£€æŸ¥åœ°å€åº“
    from config import cfg
    import json
    
    # å¦‚æœæŒ‡å®šäº†é‡‡é›†æ•°é‡
    if args.scrape:
        if run_scraper(args.scrape):
            print("âœ… åœ°å€é‡‡é›†å®Œæˆ")
        else:
            print("âš ï¸ åœ°å€é‡‡é›†å‡ºç°é—®é¢˜ï¼Œç»§ç»­å¯åŠ¨æœåŠ¡...")
    else:
        # æ£€æŸ¥åœ°å€åº“
        scraper_dir = Path("ç¾å›½åœ°å€çˆ¬è™«_å‰¯æœ¬")
        total = 0
        
        if scraper_dir.exists():
            for json_file in scraper_dir.glob("basic_addresses_*.json"):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            total += len(data)
                except:
                    pass
        
        print(f"ğŸ“‹ å½“å‰åœ°å€åº“: {total} ä¸ªåœ°å€")
        print(f"ğŸ“ åœ°å€æ¥æº: {cfg.payment.billing.address_source}")
    
    # å¯åŠ¨æœåŠ¡
    start_service()

if __name__ == '__main__':
    main()
